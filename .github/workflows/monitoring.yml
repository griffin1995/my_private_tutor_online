# CONTEXT7 SOURCE: /actions/runner - GitHub Actions continuous monitoring workflow
# CONTEXT7 SOURCE: /vercel/vercel - Vercel deployment monitoring and analytics
# MONITORING REASON: 24/7 performance monitoring with automated alerts for premium tutoring service
name: Continuous Performance Monitoring

on:
  schedule:
    # Monitor performance every 4 hours
    - cron: '0 */4 * * *'
  workflow_dispatch:
    inputs:
      monitoring_duration:
        description: 'Monitoring duration in minutes'
        required: false
        default: '60'
        type: string

env:
  NODE_VERSION: '20.x'
  LIGHTHOUSE_CI_VERSION: '0.15.x'
  PRODUCTION_URL: 'https://myprivatetutoronline-991oq6we4-jacks-projects-cf5effed.vercel.app'

jobs:
  continuous-monitoring:
    name: Performance Monitoring
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        test-scenario: [
          { name: 'Homepage', url: '/', device: 'desktop' },
          { name: 'About Page', url: '/about', device: 'desktop' },
          { name: 'Services Page', url: '/subject-tuition', device: 'desktop' },
          { name: 'Homepage Mobile', url: '/', device: 'mobile' },
          { name: 'About Page Mobile', url: '/about', device: 'mobile' }
        ]
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Setup Node.js ${{ env.NODE_VERSION }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          
      - name: Install Lighthouse CI CLI
        run: npm install -g @lhci/cli@${{ env.LIGHTHOUSE_CI_VERSION }}
        
      - name: Create monitoring configuration
        run: |
          cat > .lighthouserc.monitoring.json << 'EOF'
          {
            "ci": {
              "collect": {
                "numberOfRuns": 3,
                "url": ["${{ env.PRODUCTION_URL }}${{ matrix.test-scenario.url }}"],
                "settings": {
                  "preset": "${{ matrix.test-scenario.device }}",
                  "throttlingMethod": "simulate",
                  "onlyCategories": ["performance"],
                  "skipAudits": [
                    "unused-css-rules",
                    "unused-javascript"
                  ]
                }
              },
              "assert": {
                "preset": "lighthouse:no-pwa",
                "assertions": {
                  "first-contentful-paint": ["warn", {"maxNumericValue": 2500}],
                  "interactive": ["warn", {"maxNumericValue": 6000}],
                  "largest-contentful-paint": ["warn", {"maxNumericValue": 4500}],
                  "speed-index": ["warn", {"maxNumericValue": 4000}],
                  "cumulative-layout-shift": ["error", {"maxNumericValue": 0.15}],
                  "total-blocking-time": ["warn", {"maxNumericValue": 750}],
                  "performance": ["warn", {"minScore": 0.85}]
                }
              },
              "upload": {
                "target": "temporary-public-storage"
              }
            }
          }
          EOF
          
      - name: Monitor performance - ${{ matrix.test-scenario.name }}
        id: lighthouse-monitor
        run: |
          echo "🔍 MONITORING: ${{ matrix.test-scenario.name }} (${{ matrix.test-scenario.device }})"
          echo "🌐 URL: ${{ env.PRODUCTION_URL }}${{ matrix.test-scenario.url }}"
          echo ""
          
          # Run Lighthouse monitoring
          lhci autorun --config=.lighthouserc.monitoring.json || echo "MONITORING_FAILED=true" >> $GITHUB_OUTPUT
          
      - name: Performance monitoring report
        if: always()
        run: |
          if [ "${{ steps.lighthouse-monitor.outputs.MONITORING_FAILED }}" == "true" ]; then
            echo "⚠️ Performance monitoring detected issues for ${{ matrix.test-scenario.name }}"
            echo "📊 Royal client standards may be at risk"
          else
            echo "✅ Performance monitoring passed for ${{ matrix.test-scenario.name }}"
            echo "🏆 Royal client standards maintained"
          fi
          
  performance-alerting:
    name: Performance Alerting
    runs-on: ubuntu-latest
    needs: continuous-monitoring
    if: always()
    
    steps:
      - name: Evaluate monitoring results
        id: evaluate
        run: |
          # Check if any monitoring jobs failed
          MONITORING_RESULTS='${{ toJson(needs.continuous-monitoring.outputs) }}'
          
          # Count failed jobs
          FAILED_COUNT=0
          
          # Simple check for failures (would be more sophisticated in real implementation)
          if [ "${{ needs.continuous-monitoring.result }}" != "success" ]; then
            FAILED_COUNT=1
            echo "PERFORMANCE_ALERT=true" >> $GITHUB_OUTPUT
            echo "ALERT_LEVEL=warning" >> $GITHUB_OUTPUT
          else
            echo "PERFORMANCE_ALERT=false" >> $GITHUB_OUTPUT
          fi
          
          echo "Failed monitoring scenarios: ${FAILED_COUNT}"
          
      - name: Send performance alert
        if: steps.evaluate.outputs.PERFORMANCE_ALERT == 'true'
        run: |
          echo "🚨 PERFORMANCE ALERT - PREMIUM TUTORING SERVICE"
          echo ""
          echo "⚠️ Alert Level: ${{ steps.evaluate.outputs.ALERT_LEVEL }}"
          echo "🎯 Royal Client Standards: AT RISK"
          echo "📊 Performance Monitoring: Issues detected"
          echo ""
          echo "🔍 Affected Areas:"
          echo "• Performance metrics degraded"
          echo "• User experience may be impacted"
          echo "• Immediate investigation required"
          echo ""
          echo "🎓 Impact on Premium Tutoring Service:"
          echo "• Client experience quality"
          echo "• Brand reputation protection"
          echo "• Service delivery standards"
          echo ""
          echo "📋 Required Actions:"
          echo "1. Review performance monitoring results"
          echo "2. Investigate performance degradation"
          echo "3. Implement performance optimizations"
          echo "4. Validate fixes with royal client standards"
          echo ""
          echo "🏆 Goal: Restore royal client performance standards"
          
      - name: Performance status summary
        if: always()
        run: |
          echo "## 📊 Continuous Performance Monitoring Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ steps.evaluate.outputs.PERFORMANCE_ALERT }}" == "true" ]; then
            echo "🚨 **Performance Alert Active**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "⚠️ **Status**: Performance issues detected" >> $GITHUB_STEP_SUMMARY
            echo "🎯 **Impact**: Royal client standards at risk" >> $GITHUB_STEP_SUMMARY
            echo "📈 **Action**: Immediate investigation required" >> $GITHUB_STEP_SUMMARY
          else
            echo "✅ **All Performance Monitoring Passed**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "🏆 **Status**: Royal client standards maintained" >> $GITHUB_STEP_SUMMARY
            echo "📊 **Quality**: Premium service performance validated" >> $GITHUB_STEP_SUMMARY
            echo "🎓 **Service**: Tutoring platform performing optimally" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Monitoring Coverage" >> $GITHUB_STEP_SUMMARY
          echo "- Homepage (Desktop & Mobile)" >> $GITHUB_STEP_SUMMARY
          echo "- About Page (Desktop & Mobile)" >> $GITHUB_STEP_SUMMARY
          echo "- Services Page (Desktop)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Performance Standards" >> $GITHUB_STEP_SUMMARY
          echo "- First Contentful Paint: <2.5s" >> $GITHUB_STEP_SUMMARY
          echo "- Interactive: <6s" >> $GITHUB_STEP_SUMMARY
          echo "- Largest Contentful Paint: <4.5s" >> $GITHUB_STEP_SUMMARY
          echo "- Speed Index: <4s" >> $GITHUB_STEP_SUMMARY
          echo "- Cumulative Layout Shift: <0.15" >> $GITHUB_STEP_SUMMARY
          echo "- Total Blocking Time: <750ms" >> $GITHUB_STEP_SUMMARY
          echo "- Performance Score: ≥85%" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "🔍 **Next Monitoring**: Every 4 hours" >> $GITHUB_STEP_SUMMARY